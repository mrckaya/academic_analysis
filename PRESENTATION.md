# Akademik YayÄ±n Analizi ve AtÄ±f AÄŸÄ± Projesi

---

<div style="text-align: center; margin: 40px 0;">

# ğŸ“ Akademik YayÄ±n Analizi ve AtÄ±f AÄŸÄ± Projesi

**Makine Ã–ÄŸrenmesi ile Yazar Etki Analizi ve Network Analizi**

*Akademik araÅŸtÄ±rma topluluklarÄ±nÄ± anlamak iÃ§in geliÅŸmiÅŸ analiz sistemi*

</div>

---

## ğŸ“‹ Ä°Ã§indekiler

1. [Proje Ã–zeti](#proje-Ã¶zeti)
2. [Problem TanÄ±mÄ± ve Ã‡Ã¶zÃ¼m](#problem-tanÄ±mÄ±-ve-Ã§Ã¶zÃ¼m)
3. [Sistem Mimarisi](#sistem-mimarisi)
4. [Teknik Detaylar ve Kod Ã–rnekleri](#teknik-detaylar-ve-kod-Ã¶rnekleri)
5. [SonuÃ§lar ve GÃ¶rselleÅŸtirmeler](#sonuÃ§lar-ve-gÃ¶rselleÅŸtirmeler)
6. [Performans Metrikleri](#performans-metrikleri)
7. [SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar](#sonuÃ§-ve-gelecek-Ã§alÄ±ÅŸmalar)

---

## ğŸ¯ Proje Ã–zeti

### Proje TanÄ±mÄ±

Bu proje, **akademik yayÄ±n veritabanlarÄ±ndan** (Semantic Scholar API) toplanan verileri kullanarak:

- ğŸ“š **YayÄ±n baÅŸlÄ±klarÄ±, Ã¶zetler, yazar isimleri ve atÄ±f sayÄ±larÄ±nÄ±** otomatik olarak toplar
- ğŸ¤– **Makine Ã¶ÄŸrenmesi algoritmalarÄ±** ile alanÄ±ndaki en etkili yazarlarÄ± belirler
- ğŸ•¸ï¸ **AtÄ±f aÄŸÄ± analizi** ile araÅŸtÄ±rma gruplarÄ± arasÄ±ndaki baÄŸlantÄ±larÄ± analiz eder
- ğŸ“Š **GÃ¶rselleÅŸtirmeler** ile sonuÃ§larÄ± anlaÅŸÄ±lÄ±r ve profesyonel ÅŸekilde sunar

### Temel Ã–zellikler

| Ã–zellik | AÃ§Ä±klama |
|---------|----------|
| **API Entegrasyonu** | Semantic Scholar API ile otomatik veri toplama |
| **Veri Ä°ÅŸleme** | Pandas ile kapsamlÄ± veri temizleme ve normalizasyon |
| **Network Analizi** | NetworkX ile PageRank, centrality metrikleri |
| **ML Analizi** | Scikit-learn ve LightGBM ile Ã§oklu model karÅŸÄ±laÅŸtÄ±rmasÄ± ve etki skoru hesaplama |
| **GÃ¶rselleÅŸtirme** | Matplotlib ile profesyonel aÄŸ gÃ¶rselleÅŸtirmeleri |

---

## ğŸ¯ Proje Motivasyonu ve YaklaÅŸÄ±m

### Arka Plan

Akademik araÅŸtÄ±rma dÃ¼nyasÄ±nda, yazarlarÄ±n etkisini Ã¶lÃ§mek ve araÅŸtÄ±rma topluluklarÄ±nÄ± anlamak kritik Ã¶neme sahiptir. Geleneksel olarak, bu analizler manuel olarak yapÄ±lmakta ve sadece atÄ±f sayÄ±larÄ± gibi basit metrikler kullanÄ±lmaktadÄ±r. Ancak, modern akademik ekosistemde yazarlarÄ±n etkisi sadece atÄ±f sayÄ±larÄ±yla Ã¶lÃ§Ã¼lemez; aÄŸ iÃ§indeki konumlarÄ±, iÅŸbirlikleri ve araÅŸtÄ±rma topluluklarÄ±ndaki rolleri de Ã¶nemlidir.

### Proje AmacÄ±

Bu proje, **akademik yayÄ±n verilerini** kullanarak yazarlarÄ±n etkisini Ã§ok boyutlu bir ÅŸekilde analiz etmeyi ve araÅŸtÄ±rma topluluklarÄ± arasÄ±ndaki baÄŸlantÄ±larÄ± ortaya Ã§Ä±karmayÄ± amaÃ§lamaktadÄ±r. Proje, sadece atÄ±f sayÄ±larÄ±nÄ± deÄŸil, aynÄ± zamanda **network analizi** ve **makine Ã¶ÄŸrenmesi** tekniklerini birleÅŸtirerek daha kapsamlÄ± bir etki Ã¶lÃ§Ã¼mÃ¼ sunmaktadÄ±r.

### Metodolojik YaklaÅŸÄ±m

Proje, veriyi **4 aÅŸamalÄ± bir pipeline** ile iÅŸler:

**1. Veri Toplama ve HazÄ±rlama**
Semantic Scholar API kullanÄ±larak akademik yayÄ±n verileri otomatik olarak toplanÄ±r. Rate limiting ve retry mekanizmalarÄ± ile gÃ¼venilir veri toplama saÄŸlanÄ±r.

**2. Veri Ä°ÅŸleme ve Ã–n Ä°ÅŸleme**
Toplanan ham veriler temizlenir, yazarlar Ã§Ä±karÄ±lÄ±r ve normalize edilir. Yazar istatistikleri (toplam atÄ±f, H-index, vb.) hesaplanÄ±r.

**3. Network Analizi**
Yazarlar arasÄ± ortak yazarlÄ±k iliÅŸkileri analiz edilir. PageRank, centrality metrikleri ve topluluk tespiti algoritmalarÄ± kullanÄ±larak aÄŸdaki Ã¶nemli yazarlar ve gruplar belirlenir.

**4. Makine Ã–ÄŸrenmesi Analizi**
Yazar istatistikleri ve network metrikleri birleÅŸtirilerek Ã¶zellik vektÃ¶rleri oluÅŸturulur. AÄŸÄ±rlÄ±klÄ± kombinasyon ile etki skorlarÄ± hesaplanÄ±r, tahmin modelleri eÄŸitilir ve yazarlar benzerliklerine gÃ¶re kÃ¼melendirilir.

### Ä°novatif Ã–zellikler

- **Ã‡oklu Metrik Kombinasyonu:** Sadece atÄ±f sayÄ±larÄ± deÄŸil, network metrikleri (PageRank, centrality) de etki skoruna dahil edilir
- **Otomatik Pipeline:** TÃ¼m analiz adÄ±mlarÄ± otomatik olarak Ã§alÄ±ÅŸÄ±r, manuel mÃ¼dahale gerektirmez
- **Ã–lÃ§eklenebilir Mimari:** Binlerce yazar ve yayÄ±n iÃ§in Ã§alÄ±ÅŸabilir
- **GÃ¶rselleÅŸtirme:** KullanÄ±cÄ± dostu ve anlaÅŸÄ±lÄ±r aÄŸ gÃ¶rselleÅŸtirmeleri

---

## ğŸ—ï¸ Sistem Mimarisi

### ModÃ¼ler YapÄ±

Proje, **modÃ¼ler ve geniÅŸletilebilir** bir mimariye sahiptir:

```
academic_analysis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_collector.py      # API entegrasyonu ve veri toplama
â”‚   â”œâ”€â”€ data_processor.py       # Veri temizleme ve istatistik hesaplama
â”‚   â”œâ”€â”€ citation_network.py    # Network analizi ve gÃ¶rselleÅŸtirme
â”‚   â”œâ”€â”€ ml_analyzer.py         # ML modelleri ve etki skoru
â”‚   â””â”€â”€ main.py                # Ana uygulama orkestrasyonu
â”œâ”€â”€ data/
â”‚   â””â”€â”€ publications.csv       # Toplanan ham veriler (baÅŸlÄ±k, Ã¶zet, yazarlar, atÄ±f sayÄ±sÄ±)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ citation_network.png   # AÄŸ gÃ¶rselleÅŸtirmesi (ortak yazarlÄ±k aÄŸÄ±)
â”‚   â”œâ”€â”€ author_impact_scores.csv  # TÃ¼m yazarlar iÃ§in etki skorlarÄ± ve metrikler
â”‚   â”œâ”€â”€ network_metrics.csv    # AÄŸ analizi metrikleri (PageRank, centrality vb.)
â”‚   â”œâ”€â”€ top_influential_authors.csv  # En etkili 20 yazarÄ±n Ã¶zet bilgileri
â”‚   â””â”€â”€ clustered_authors.csv  # KÃ¼meleme sonuÃ§larÄ± (benzer yazarlar gruplandÄ±rÄ±lmÄ±ÅŸ)
â””â”€â”€ requirements.txt           # Python baÄŸÄ±mlÄ±lÄ±klarÄ± (pandas, networkx, scikit-learn vb.)
```

### Veri AkÄ±ÅŸÄ±

```
API Verileri â†’ CSV â†’ DataFrame â†’ Ä°ÅŸleme â†’ Analiz â†’ SonuÃ§lar
     â†“           â†“        â†“          â†“         â†“         â†“
  JSON      KayÄ±t    Temizleme   Network   ML      GÃ¶rselleÅŸtirme
```

---

## ğŸ’» Teknik Detaylar ve Kod Ã–rnekleri

### 1. Veri Toplama ModÃ¼lÃ¼

`src/data_collector.py`

 Bu modÃ¼l, Semantic Scholar API kullanarak akademik yayÄ±n verilerini toplar. `ScholarDataCollector` sÄ±nÄ±fÄ±, API ile iletiÅŸim kurarak yayÄ±n baÅŸlÄ±klarÄ±, Ã¶zetler, yazar isimleri ve atÄ±f sayÄ±larÄ±nÄ± Ã§eker. Rate limiting, retry mekanizmasÄ± ve exponential backoff stratejileri ile gÃ¼venilir ve kesintisiz veri toplama saÄŸlar. Toplanan veriler CSV formatÄ±nda `data/publications.csv` dosyasÄ±na kaydedilir.

#### API Entegrasyonu

Semantic Scholar API ile baÄŸlantÄ± kurmak iÃ§in `ScholarDataCollector` sÄ±nÄ±fÄ±nÄ±n baÅŸlatÄ±lmasÄ± ve API parametrelerinin (API key, delay, timeout) yapÄ±landÄ±rÄ±lmasÄ±.

```python
class ScholarDataCollector:
    """Semantic Scholar API ile veri toplama sÄ±nÄ±fÄ±"""
    
    def __init__(self, api_key=None, delay=3.0, timeout=30.0):
        """
        Args:
            api_key: API key (opsiyonel, rate limit artÄ±rÄ±r)
            delay: Ä°stekler arasÄ± bekleme (rate limiting iÃ§in)
            timeout: Her istek iÃ§in timeout sÃ¼resi
        """
        self.api_key = api_key
        self.delay = delay
        self.timeout = timeout
        self.api_base_url = "https://api.semanticscholar.org/graph/v1"
```

**Ã–zellikler:**

- **Rate Limiting:** API'nin izin verdiÄŸi istek limitlerine (100 istek/5 dakika) uyum saÄŸlamak iÃ§in her istek arasÄ±nda otomatik bekleme sÃ¼resi eklenir. Bu sayede API'den engellenme riski minimize edilir ve veri toplama sÃ¼reci kesintisiz devam eder.

- **Retry MekanizmasÄ±:** API'den 429 (Too Many Requests) hatasÄ± alÄ±ndÄ±ÄŸÄ±nda, sistem otomatik olarak belirtilen sÃ¼re kadar bekler ve isteÄŸi tekrar dener. Maksimum 3 deneme yapÄ±lÄ±r, bÃ¶ylece geÃ§ici hatalar otomatik olarak aÅŸÄ±lÄ±r.

- **Exponential Backoff:** Timeout veya aÄŸ hatalarÄ± durumunda, her baÅŸarÄ±sÄ±z denemede bekleme sÃ¼resi katlanarak artar (2 saniye â†’ 4 saniye â†’ 8 saniye). Bu strateji, sunucuya aÅŸÄ±rÄ± yÃ¼k bindirmeyi Ã¶nler ve baÅŸarÄ± ÅŸansÄ±nÄ± artÄ±rÄ±r.

- **Otomatik Pagination:** Semantic Scholar API her istekte maksimum 100 sonuÃ§ dÃ¶ndÃ¼rÃ¼r. Sistem, daha fazla sonuÃ§ gerektiÄŸinde otomatik olarak sonraki sayfalarÄ± (offset kullanarak) talep eder ve tÃ¼m sonuÃ§larÄ± birleÅŸtirir. KullanÄ±cÄ± sadece toplam sonuÃ§ sayÄ±sÄ±nÄ± belirtir, pagination detaylarÄ± otomatik yÃ¶netilir.

#### Veri Toplama Kodu

API'ye sorgu gÃ¶ndererek yayÄ±n verilerini Ã§eken ve pagination ile tÃ¼m sonuÃ§larÄ± toplayan ana fonksiyon.

```python
def search_publications(self, query: str, max_results: int = 100):
    """Semantic Scholar API ile yayÄ±n arama"""
    publications = []
    offset = 0
    limit = min(100, max_results)  # API limit: 100 sonuÃ§/istek
    
    while len(publications) < max_results:
        # API istek parametreleri
        params = {
            'query': query,
            'limit': limit,
            'offset': offset,
            'fields': 'title,abstract,authors,citationCount,externalIds,url'
        }
        
        # API isteÄŸi gÃ¶nder (retry mekanizmasÄ± ile)
        response_data = self._api_request('paper/search', params)
        
        if not response_data or 'data' not in response_data:
            break
        
        # Her yayÄ±nÄ± parse et
        for paper in response_data.get('data', []):
            pub_data = self._parse_api_paper(paper)
            if pub_data and pub_data['title']:
                publications.append(pub_data)
        
        # Rate limiting iÃ§in bekle
        time.sleep(max(self.delay, 3.0))
        offset += limit
    
    return publications
```

**Retry MekanizmasÄ±:**

```python
def _api_request(self, endpoint: str, params: Dict = None, max_retries: int = 3):
    """API isteÄŸi gÃ¶nderir (retry mekanizmasÄ± ile)"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)
            
            # 429 hatasÄ± (Rate Limit) - bekleyip tekrar dene
            if response.status_code == 429:
                retry_after = int(response.headers.get('Retry-After', 60))
                wait_time = min(retry_after, 120)
                
                if attempt < max_retries - 1:
                    time.sleep(wait_time)
                    continue
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.Timeout:
            # Exponential backoff
            wait_time = (attempt + 1) * 5
            time.sleep(wait_time)
            continue
```

---

### 2. Veri Ä°ÅŸleme ModÃ¼lÃ¼

`src/data_processor.py`

Bu modÃ¼l, toplanan ham verileri temizler ve yazar bazlÄ± istatistikler hesaplar. `DataProcessor` sÄ±nÄ±fÄ±, eksik deÄŸerleri doldurur, yazar listelerini normalize eder, duplicate yayÄ±nlarÄ± kaldÄ±rÄ±r ve her yazar iÃ§in yayÄ±n sayÄ±sÄ±, toplam atÄ±f sayÄ±sÄ±, ortalama atÄ±f sayÄ±sÄ± ve H-index gibi metrikleri hesaplar. Ä°ÅŸlenmiÅŸ veriler `data/authors.csv` ve `data/author_stats.csv` dosyalarÄ±na kaydedilir.

#### Veri Temizleme

Ham verilerden eksik deÄŸerleri doldurma, yazar listelerini normalize etme, duplicate yayÄ±nlarÄ± kaldÄ±rma ve veri tiplerini dÃ¼zeltme iÅŸlemleri.

```python
class DataProcessor:
    """Veri iÅŸleme ve temizleme sÄ±nÄ±fÄ±"""
    
    def clean_data(self) -> pd.DataFrame:
        """Verileri temizler ve standartlaÅŸtÄ±rÄ±r"""
        df = self.df.copy()
        
        # Eksik deÄŸerleri doldur
        df['title'] = df['title'].fillna('')
        df['abstract'] = df['abstract'].fillna('')
        df['citation_count'] = pd.to_numeric(df['citation_count'], errors='coerce').fillna(0)
        
        # Yazar listelerini temizle
        df['authors'] = df['authors'].apply(self._clean_author_list)
        
        # BoÅŸ baÅŸlÄ±klÄ± yayÄ±nlarÄ± kaldÄ±r
        df = df[df['title'].str.strip() != '']
        
        # Duplicate'leri kaldÄ±r
        df = df.drop_duplicates(subset=['title'], keep='first')
        
        return df
```

#### Yazar Ä°statistikleri Hesaplama

Her yazar iÃ§in yayÄ±n sayÄ±sÄ±, toplam atÄ±f sayÄ±sÄ±, ortalama atÄ±f sayÄ±sÄ± ve H-index gibi akademik performans metriklerini hesaplama.

```python
def calculate_author_stats(self, authors_df: pd.DataFrame) -> pd.DataFrame:
    """Yazarlar iÃ§in istatistikler hesaplar"""
    
    # Yazar bazÄ±nda grupla
    grouped = authors_df.groupby('author_normalized')
    
    # Ä°statistikleri hesapla
    author_stats = pd.DataFrame({
        'publication_count': grouped['publication_title'].count(),
        'total_citations': grouped['citation_count'].sum(),
        'avg_citations_per_paper': grouped['citation_count'].mean()
    }).reset_index()
    
    # H-index hesapla
    author_stats['h_index_approx'] = author_stats.apply(
        lambda row: self._calculate_h_index_approx(
            authors_df[authors_df['author_normalized'] == row['author_name']]['citation_count']
        ),
        axis=1
    )
    
    return author_stats.sort_values('total_citations', ascending=False)
```

**H-index Hesaplama:**

**H-index Nedir?**

H-index (Hirsch index), bir araÅŸtÄ±rmacÄ±nÄ±n akademik etkisini Ã¶lÃ§mek iÃ§in kullanÄ±lan bir metrikdir. 2005 yÄ±lÄ±nda fizikÃ§i Jorge E. Hirsch tarafÄ±ndan geliÅŸtirilmiÅŸtir.

**TanÄ±m:** Bir araÅŸtÄ±rmacÄ±nÄ±n H-index deÄŸeri, o araÅŸtÄ±rmacÄ±nÄ±n en az H adet yayÄ±nÄ±nÄ±n, her birinin en az H kez atÄ±f almÄ±ÅŸ olmasÄ± anlamÄ±na gelir.

**Ã–rnek:**
- Bir araÅŸtÄ±rmacÄ±nÄ±n 5 yayÄ±nÄ± var ve atÄ±f sayÄ±larÄ±: [10, 8, 5, 3, 2]
- SÄ±ralama (azalan): [10, 8, 5, 3, 2]
- Kontrol:
  - 1. yayÄ±n: 10 â‰¥ 1? âœ… (H â‰¥ 1)
  - 2. yayÄ±n: 8 â‰¥ 2? âœ… (H â‰¥ 2)
  - 3. yayÄ±n: 5 â‰¥ 3? âœ… (H â‰¥ 3)
  - 4. yayÄ±n: 3 â‰¥ 4? âŒ (H = 3)
- **SonuÃ§: H-index = 3** (En az 3 yayÄ±nÄ±, her biri en az 3 atÄ±f almÄ±ÅŸ)

**Neden Ã–nemli?**
- Sadece toplam atÄ±f sayÄ±sÄ±na bakmak yerine, yayÄ±nlarÄ±n kalitesini ve tutarlÄ±lÄ±ÄŸÄ±nÄ± gÃ¶sterir
- Bir araÅŸtÄ±rmacÄ±nÄ±n hem Ã¼retkenliÄŸini (yayÄ±n sayÄ±sÄ±) hem de etkisini (atÄ±f sayÄ±sÄ±) dengeli bir ÅŸekilde Ã¶lÃ§er
- Akademik dÃ¼nyada yaygÄ±n olarak kabul gÃ¶ren bir performans gÃ¶stergesidir

```python
def _calculate_h_index_approx(self, citations: pd.Series) -> int:
    """YaklaÅŸÄ±k H-index hesaplar"""
    if len(citations) == 0:
        return 0
    
    # AtÄ±f sayÄ±larÄ±nÄ± azalan sÄ±raya gÃ¶re sÄ±rala
    sorted_citations = sorted(citations, reverse=True)
    h_index = 0
    
    # H-index: En az h yayÄ±nÄ±, her biri en az h atÄ±f almÄ±ÅŸ
    for i, cit in enumerate(sorted_citations):
        if cit >= i + 1:
            h_index = i + 1
        else:
            break
    
    return h_index
```

---

### 3. Network Analizi ModÃ¼lÃ¼

`src/citation_network.py`

Bu modÃ¼l, yazarlar arasÄ± ortak yazarlÄ±k iliÅŸkilerini analiz eder ve gÃ¶rselleÅŸtirir. `CitationNetworkAnalyzer` sÄ±nÄ±fÄ±, aynÄ± yayÄ±nda birlikte yazmÄ±ÅŸ yazarlar arasÄ±nda baÄŸlantÄ±lar (edge) oluÅŸturarak bir aÄŸ (graph) yapÄ±sÄ± kurar. NetworkX kÃ¼tÃ¼phanesi kullanÄ±larak PageRank, degree centrality, betweenness centrality gibi metrikler hesaplanÄ±r. Louvain algoritmasÄ± ile araÅŸtÄ±rma topluluklarÄ± tespit edilir ve sonuÃ§lar `results/citation_network.png` gÃ¶rseli ve `results/network_metrics.csv` dosyasÄ±na kaydedilir.

#### Ortak YazarlÄ±k AÄŸÄ± OluÅŸturma

AynÄ± yayÄ±nda birlikte yazmÄ±ÅŸ yazarlar arasÄ±nda baÄŸlantÄ±lar (edge) oluÅŸturarak, yazarlar arasÄ± iÅŸbirliÄŸi iliÅŸkilerini gÃ¶steren bir aÄŸ (graph) yapÄ±sÄ± kurma.

```python
def build_coauthorship_network(self) -> nx.Graph:
    """Yazarlar arasÄ± ortak yazarlÄ±k aÄŸÄ±nÄ± oluÅŸturur"""
    self.coauthorship_graph = nx.Graph()
    
    # Her yayÄ±ndaki yazarlarÄ± iÅŸle
    for idx, row in self.publications_df.iterrows():
        authors = row.get('authors', [])
        
        # En az 2 yazar olmalÄ± (ortak yazarlÄ±k iÃ§in)
        if not authors or len(authors) < 2:
            continue
        
        # Yazar isimlerini normalize et
        normalized_authors = [a.lower().strip() for a in authors]
        
        # Her yazar Ã§ifti arasÄ±nda edge oluÅŸtur
        # Ã–rnek: [A, B, C] -> (A-B), (A-C), (B-C) baÄŸlantÄ±larÄ±
        for i in range(len(normalized_authors)):
            for j in range(i + 1, len(normalized_authors)):
                author1 = normalized_authors[i]
                author2 = normalized_authors[j]
                
                if self.coauthorship_graph.has_edge(author1, author2):
                    # Edge zaten varsa, aÄŸÄ±rlÄ±ÄŸÄ± artÄ±r
                    self.coauthorship_graph[author1][author2]['weight'] += 1
                else:
                    # Yeni edge oluÅŸtur
                    self.coauthorship_graph.add_edge(
                        author1, author2, weight=1
                    )
    
    return self.coauthorship_graph
```

#### AÄŸ Metrikleri Hesaplama

NetworkX kÃ¼tÃ¼phanesi kullanarak her yazar iÃ§in PageRank, degree centrality, betweenness centrality, closeness centrality ve eigenvector centrality gibi aÄŸ analizi metriklerini hesaplama.

```python
def calculate_network_metrics(self) -> pd.DataFrame:
    """AÄŸ metriklerini hesaplar"""
    
    # NetworkX ile metrikleri hesapla
    degree_centrality = nx.degree_centrality(self.coauthorship_graph)
    betweenness_centrality = nx.betweenness_centrality(self.coauthorship_graph)
    closeness_centrality = nx.closeness_centrality(self.coauthorship_graph)
    eigenvector_centrality = nx.eigenvector_centrality(self.coauthorship_graph)
    pagerank = nx.pagerank(self.coauthorship_graph)
    
    # Her yazar iÃ§in metrikleri topla
    metrics = []
    for node in self.coauthorship_graph.nodes():
        metrics.append({
            'author_name': node,
            'degree': self.coauthorship_graph.degree(node),
            'degree_centrality': degree_centrality.get(node, 0),
            'betweenness_centrality': betweenness_centrality.get(node, 0),
            'closeness_centrality': closeness_centrality.get(node, 0),
            'eigenvector_centrality': eigenvector_centrality.get(node, 0),
            'pagerank': pagerank.get(node, 0)
        })
    
    return pd.DataFrame(metrics)
```

**Metrik AÃ§Ä±klamalarÄ±:**

| Metrik | AÃ§Ä±klama |
|--------|----------|
| **Degree** | Direkt baÄŸlantÄ± sayÄ±sÄ± (kaÃ§ yazarla ortak Ã§alÄ±ÅŸmÄ±ÅŸ) |
| **PageRank** | Genel Ã¶nem skoru (Google'Ä±n kullandÄ±ÄŸÄ± algoritma) |
| **Betweenness Centrality** | KÃ¶prÃ¼ rolÃ¼ (aÄŸdaki kritik geÃ§iÅŸ noktalarÄ±) |
| **Closeness Centrality** | DiÄŸer yazarlara yakÄ±nlÄ±k (ortalama mesafe) |
| **Eigenvector Centrality** | Ã–nemli yazarlarla baÄŸlantÄ± (prestij) |

---

### 4. Makine Ã–ÄŸrenmesi ModÃ¼lÃ¼

`src/ml_analyzer.py`

Bu modÃ¼l, yazar istatistikleri ve aÄŸ metriklerini birleÅŸtirerek makine Ã¶ÄŸrenmesi analizleri yapar. `MLAnalyzer` sÄ±nÄ±fÄ±, Ã¶zellik vektÃ¶rleri oluÅŸturur, aÄŸÄ±rlÄ±klÄ± etki skorlarÄ± hesaplar, Random Forest ile atÄ±f sayÄ±sÄ± tahmin modelleri eÄŸitir ve KMeans/DBSCAN algoritmalarÄ± ile yazarlarÄ± benzerliklerine gÃ¶re kÃ¼meleme yapar. SonuÃ§lar `results/author_impact_scores.csv`, `results/top_influential_authors.csv` ve `results/clustered_authors.csv` dosyalarÄ±na kaydedilir.

#### Ã–zellik VektÃ¶rÃ¼ OluÅŸturma

Yazar istatistikleri ve aÄŸ metriklerini birleÅŸtirerek makine Ã¶ÄŸrenmesi algoritmalarÄ± iÃ§in kullanÄ±lacak Ã¶zellik vektÃ¶rlerini oluÅŸturma ve normalizasyon iÅŸlemleri.

```python
def create_features(self) -> pd.DataFrame:
    """ML iÃ§in Ã¶zellik vektÃ¶rÃ¼ oluÅŸturur"""
    
    # Yazar istatistikleri ve aÄŸ metriklerini birleÅŸtir
    merged = pd.merge(
        self.author_stats_df,
        self.network_metrics_df,
        on='author_name',
        how='inner'
    )
    
    # Ã–zellikleri seÃ§
    feature_columns = [
        'publication_count',
        'total_citations',
        'avg_citations_per_paper',
        'h_index_approx',
        'degree',
        'degree_centrality',
        'betweenness_centrality',
        'closeness_centrality',
        'eigenvector_centrality',
        'pagerank'
    ]
    
    # Eksik deÄŸerleri doldur
    self.feature_df = merged[['author_name'] + feature_columns].copy()
    self.feature_df[feature_columns] = self.feature_df[feature_columns].fillna(0)
    
    return self.feature_df
```

#### Etki Skoru Hesaplama

YazarlarÄ±n akademik etkisini Ã¶lÃ§mek iÃ§in Ã§oklu Ã¶zellikleri (atÄ±f sayÄ±sÄ±, H-index, PageRank, aÄŸ metrikleri vb.) aÄŸÄ±rlÄ±klÄ± olarak birleÅŸtirerek 0-100 arasÄ± bir etki skoru hesaplama. Bu skor, yazarlarÄ±n akademik performanslarÄ±nÄ± tek bir sayÄ± ile karÅŸÄ±laÅŸtÄ±rmayÄ± saÄŸlar.

**YaklaÅŸÄ±m:**
1. **Ã–zellik Normalizasyonu:** FarklÄ± Ã¶lÃ§eklerdeki Ã¶zellikleri (Ã¶rneÄŸin, atÄ±f sayÄ±larÄ± binlerce, PageRank 0-1 arasÄ±) StandardScaler ile normalize ederek aynÄ± Ã¶lÃ§eÄŸe getiririz.
2. **AÄŸÄ±rlÄ±klÄ± Toplama:** Her Ã¶zelliÄŸe Ã¶nemine gÃ¶re aÄŸÄ±rlÄ±k verilir (Ã¶rneÄŸin, toplam atÄ±f sayÄ±sÄ± %25, H-index %20, PageRank %15 aÄŸÄ±rlÄ±ÄŸÄ±na sahiptir).
3. **Skor Hesaplama:** Normalize edilmiÅŸ Ã¶zellikler aÄŸÄ±rlÄ±klarÄ±yla Ã§arpÄ±lÄ±p toplanÄ±r ve min-max normalizasyonu ile 0-100 arasÄ± bir skora dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
4. **SonuÃ§:** YÃ¼ksek skorlu yazarlar, hem yÃ¼ksek atÄ±f sayÄ±sÄ±na hem de aÄŸ iÃ§indeki Ã¶nemli konumlarÄ±na sahip olan etkili araÅŸtÄ±rmacÄ±lardÄ±r.

```python
def calculate_impact_score(self) -> pd.DataFrame:
    """Yazar etki skorunu hesaplar (0-100 arasÄ±)"""
    
    feature_cols = [col for col in self.feature_df.columns 
                   if col not in ['author_name']]
    
    # Ã–zellikleri normalize et (StandardScaler)
    X = self.feature_df[feature_cols].values
    X_scaled = self.scaler.fit_transform(X)
    
    # AÄŸÄ±rlÄ±klÄ± etki skoru hesapla
    weights = {
        'total_citations': 0.25,      # En Ã¶nemli
        'h_index_approx': 0.20,
        'pagerank': 0.15,
        'publication_count': 0.10,
        'betweenness_centrality': 0.10,
        'eigenvector_centrality': 0.10,
        'degree_centrality': 0.05,
        'closeness_centrality': 0.05
    }
    
    impact_score = np.zeros(len(self.feature_df))
    
    # Her Ã¶zelliÄŸi aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arp ve topla
    for i, col in enumerate(feature_cols):
        if col in weights:
            impact_score += X_scaled[:, i] * weights[col]
    
    # Min-max normalizasyonu (0-100 arasÄ±)
    if impact_score.max() > impact_score.min():
        impact_score = (impact_score - impact_score.min()) / \
                      (impact_score.max() - impact_score.min()) * 100
    
    self.feature_df['impact_score'] = impact_score
    return self.feature_df.sort_values('impact_score', ascending=False)
```

**Etki Skoru FormÃ¼lÃ¼:**

```
Impact Score = Î£ (Normalized_Feature_i Ã— Weight_i)

Ã–rnek Hesaplama:

1. Total Citations (normalized): 0.85, Weight: 0.25 â†’ 0.2125
   (Normalize edilmiÅŸ atÄ±f sayÄ±sÄ± (0.85) ile aÄŸÄ±rlÄ±ÄŸÄ± (0.25) Ã§arpÄ±lÄ±r: 0.85 Ã— 0.25 = 0.2125)

2. H-index (normalized): 0.70, Weight: 0.20 â†’ 0.1400
   (Normalize edilmiÅŸ H-index deÄŸeri (0.70) ile aÄŸÄ±rlÄ±ÄŸÄ± (0.20) Ã§arpÄ±lÄ±r: 0.70 Ã— 0.20 = 0.1400)

3. PageRank (normalized): 0.60, Weight: 0.15 â†’ 0.0900
   (Normalize edilmiÅŸ PageRank deÄŸeri (0.60) ile aÄŸÄ±rlÄ±ÄŸÄ± (0.15) Ã§arpÄ±lÄ±r: 0.60 Ã— 0.15 = 0.0900)

4. ... (diÄŸer Ã¶zellikler: publication_count, betweenness_centrality, vb.)
   (Kalan tÃ¼m Ã¶zellikler iÃ§in aynÄ± iÅŸlem yapÄ±lÄ±r ve her biri kendi aÄŸÄ±rlÄ±ÄŸÄ± ile Ã§arpÄ±lÄ±r.)

5. â†’ Toplam: 0.75 â†’ Min-Max normalize â†’ 75/100
   (TÃ¼m aÄŸÄ±rlÄ±klÄ± deÄŸerler toplanÄ±r (0.2125 + 0.1400 + 0.0900 + ... = 0.75). 
   Bu ham skor, veri setindeki minimum ve maksimum deÄŸerler arasÄ±nda normalize edilerek 
   0-100 arasÄ± bir skora dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Bu Ã¶rnekte 0.75 deÄŸeri, normalize edildikten sonra 75/100 olur.)
```

#### AtÄ±f Tahmin Modeli

Birden fazla makine Ã¶ÄŸrenmesi algoritmasÄ± (Random Forest, LightGBM, Decision Tree) kullanarak yazarlarÄ±n gelecekteki atÄ±f sayÄ±larÄ±nÄ± tahmin eden modeller eÄŸitme ve performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma.

**1. Random Forest Regressor**

```python
if model_name == 'rf':
    # Random Forest Regressor
    model = RandomForestRegressor(
        n_estimators=100,  # 100 aÄŸaÃ§
        max_depth=10,      # Maksimum derinlik
        random_state=42,   # Tekrarlanabilirlik
        n_jobs=-1          # TÃ¼m CPU Ã§ekirdeklerini kullan
    )
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
```

**2. LightGBM Regressor**

```python
elif model_name == 'lgbm':
    # LightGBM Regressor (Gradient Boosting)
    model = lgb.LGBMRegressor(
        n_estimators=100,    # 100 aÄŸaÃ§
        max_depth=10,        # Maksimum derinlik
        learning_rate=0.1,   # Ã–ÄŸrenme hÄ±zÄ±
        random_state=42,     # Tekrarlanabilirlik
        n_jobs=-1,           # TÃ¼m CPU Ã§ekirdeklerini kullan
        verbose=-1           # Log mesajlarÄ±nÄ± gizle
    )
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
```

**3. Decision Tree Regressor**

```python
elif model_name == 'dt':
    # Decision Tree Regressor
    model = DecisionTreeRegressor(
        max_depth=10,      # Maksimum derinlik (overfitting'i Ã¶nlemek iÃ§in)
        random_state=42    # Tekrarlanabilirlik
    )
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
```

**Model KarÅŸÄ±laÅŸtÄ±rmasÄ± ve En Ä°yi Model SeÃ§imi:**

```python
# Her model iÃ§in performans metrikleri hesapla
for model_name in ['rf', 'lgbm', 'dt']:
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    results[model_name] = {
        'r2_score': r2,
        'rmse': rmse
    }

# En iyi modeli bul (RÂ² skoruna gÃ¶re)
best_model_name = max(results.keys(), key=lambda x: results[x]['r2_score'])
```

**Ã‡Ä±ktÄ±:**
- TÃ¼m modellerin RÂ² ve RMSE skorlarÄ±
- En iyi performans gÃ¶steren model
- En iyi modelin Ã¶zellik Ã¶nemleri (feature importance)

**Ã–rnek SonuÃ§lar (GerÃ§ek Veri Seti ile):**

```
[INFO] Model Performans Karsilastirmasi:
------------------------------------------------------------
  RF           | RÂ² =  0.7251 | RMSE =  9988.18
  LGBM         | RÂ² =  0.7600 | RMSE =  9332.00
  DT           | RÂ² =  0.6595 | RMSE = 11115.87
```

**SonuÃ§ Analizi:**

**[BEST] En Iyi Model: LightGBM (LGBM)**
- RÂ² = 0.7600 (Model, veri varyansÄ±nÄ±n %76'sÄ±nÄ± aÃ§Ä±klÄ±yor)
- RMSE = 9332.00 (Tahminler ortalama Â±9332 atÄ±f sapma gÃ¶steriyor)

**Model SÄ±ralamasÄ±:**
1. **LightGBM** (RÂ² = 0.76) - En iyi performans, gradient boosting ile gÃ¼Ã§lÃ¼ Ã¶ÄŸrenme
2. **Random Forest** (RÂ² = 0.73) - Ensemble yÃ¶ntemi ile iyi performans
3. **Decision Tree** (RÂ² = 0.66) - Basit model, daha dÃ¼ÅŸÃ¼k performans

**RÂ² DeÄŸerlerinin Neden YÃ¼ksek OlmadÄ±ÄŸÄ±:**

RÂ² deÄŸerleri (0.66-0.76 arasÄ±) orta seviyede gÃ¶rÃ¼nse de, bu durum normal ve beklenen bir sonuÃ§tur:

1. **Akademik AtÄ±f SayÄ±sÄ±nÄ±n DoÄŸasÄ±:** AtÄ±f sayÄ±larÄ± Ã§ok deÄŸiÅŸken ve tahmin edilmesi zor bir metrik. Bir yazarÄ±n atÄ±f sayÄ±sÄ± sadece Ã¶zelliklerine deÄŸil, yayÄ±nÄ±n kalitesi, zamanlama, ÅŸans faktÃ¶rleri gibi birÃ§ok faktÃ¶re baÄŸlÄ±dÄ±r.

2. **SÄ±nÄ±rlÄ± Ã–zellik Seti:** Model, sadece yazar istatistikleri ve aÄŸ metriklerini kullanÄ±yor. YayÄ±n iÃ§eriÄŸi, dergi kalitesi, araÅŸtÄ±rma alanÄ± gibi Ã¶nemli faktÃ¶rler modele dahil deÄŸil.

3. **Veri Seti Boyutu:** KÃ¼Ã§Ã¼k-orta Ã¶lÃ§ekli veri setlerinde ML modelleri tam potansiyeline ulaÅŸamayabilir.

4. **RÂ² = 0.76 Ä°yi Bir SonuÃ§:** Akademik literatÃ¼rde, sosyal bilimler ve davranÄ±ÅŸsal veriler iÃ§in RÂ² > 0.7 deÄŸerleri genellikle "iyi" veya "kabul edilebilir" olarak kabul edilir. %76'lÄ±k aÃ§Ä±klama gÃ¼cÃ¼, modelin yazar etkisini Ã¶lÃ§mede anlamlÄ± bir katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir.

5. **Pratik KullanÄ±m:** Model, yazarlarÄ± etki skorlarÄ±na gÃ¶re sÄ±ralamak ve genel trendleri tahmin etmek iÃ§in yeterli doÄŸrulukta Ã§alÄ±ÅŸmaktadÄ±r.

---

### 5. Ana Uygulama AkÄ±ÅŸÄ±

Ana uygulama fonksiyonu (`main()`), tÃ¼m analiz adÄ±mlarÄ±nÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rarak veri toplamadan sonuÃ§larÄ±n kaydedilmesine kadar tÃ¼m sÃ¼reci otomatikleÅŸtirir. Her adÄ±m bir Ã¶nceki adÄ±mÄ±n Ã§Ä±ktÄ±sÄ±nÄ± kullanarak pipeline ÅŸeklinde Ã§alÄ±ÅŸÄ±r ve sonuÃ§larÄ± CSV dosyalarÄ±na ve gÃ¶rselleÅŸtirmelere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

```python
def main():
    """Ana uygulama fonksiyonu - TÃ¼m analiz adÄ±mlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r"""
    
    # 1. VERÄ° TOPLAMA
    collector = ScholarDataCollector(
        api_key=None,
        delay=3.0,
        timeout=30.0
    )
    
    queries = ["machine learning", "deep learning", "neural networks"]
    df_publications = collector.collect_multiple_queries(
        queries, 
        max_results_per_query=50
    )
    collector.save_to_csv(df_publications, "data/publications.csv")
    
    # 2. VERÄ° Ä°ÅLEME
    processor = DataProcessor(df_publications)
    df_cleaned = processor.clean_data()
    
    df_authors = processor.extract_authors()
    df_authors = processor.normalize_author_names(df_authors)
    author_stats = processor.calculate_author_stats(df_authors)
    
    # 3. NETWORK ANALÄ°ZÄ°
    network_analyzer = CitationNetworkAnalyzer(df_cleaned, df_authors)
    coauthorship_graph = network_analyzer.build_coauthorship_network()
    network_metrics = network_analyzer.calculate_network_metrics()
    communities = network_analyzer.find_research_communities()
    
    # 4. ML ANALÄ°ZÄ°
    ml_analyzer = MLAnalyzer(author_stats, network_metrics)
    feature_df = ml_analyzer.create_features()
    impact_df = ml_analyzer.calculate_impact_score()
    
    # Birden fazla ML modeli ile tahmin (RF, LGBM, DT)
    print("KullanÄ±lan ML YÃ¶ntemleri: Random Forest, LightGBM, Decision Tree")
    prediction_results = ml_analyzer.predict_citations()
    
    # Model performans karÅŸÄ±laÅŸtÄ±rmasÄ±
    print("\n[INFO] Model Performans Karsilastirmasi:")
    for model_name, metrics in prediction_results['results'].items():
        print(f"  {metrics['model_name']:12s} | RÂ² = {metrics['r2_score']:7.4f} | RMSE = {metrics['rmse']:8.2f}")
    
    # En iyi modeli gÃ¶ster
    if prediction_results['best_model']:
        best = prediction_results['best_model']
        print(f"\n[BEST] En Iyi Model: {best.upper()}")
        print(f"   RÂ² Skoru: {prediction_results['results'][best]['r2_score']:.4f}")
        print(f"   RMSE: {prediction_results['results'][best]['rmse']:.2f}")
    
    # En Ã¶nemli Ã¶zellikler
    if not prediction_results['feature_importance'].empty:
        print("\nEn Ã–nemli Ã–zellikler (En Ä°yi Modele GÃ¶re):")
        print(prediction_results['feature_importance'].head(5))
    
    # KÃ¼meleme
    clustered_df = ml_analyzer.cluster_authors(n_clusters=5)
    top_influential = ml_analyzer.get_top_influential_authors(top_n=10)
    
    # 5. GÃ–RSELLEÅTÄ°RME
    network_analyzer.visualize_network(
        top_authors=50,
        save_path="results/citation_network.png"
    )
    
    # 6. SONUÃ‡LARI KAYDET
    impact_df.to_csv("results/author_impact_scores.csv", index=False)
    network_metrics.to_csv("results/network_metrics.csv", index=False)
    top_influential.to_csv("results/top_influential_authors.csv", index=False)
    clustered_df.to_csv("results/clustered_authors.csv", index=False)
```

---

## ğŸ“Š SonuÃ§lar ve GÃ¶rselleÅŸtirmeler

### 1. Yazar Ä°statistikleri

**Ã–rnek Ã‡Ä±ktÄ±:**

```
En Ã‡ok AtÄ±f Alan 10 Yazar:
            author_name  total_citations  publication_count  h_index_approx
        i. sutskever           237150                  7               7
  geoffrey e. hinton           222225                  6               6
        a. krizhevsky           165704                  2               2
       yoshua bengio            81317                  5               5
```

### 2. Network GÃ¶rselleÅŸtirmesi

**GÃ¶rsel Ã–zellikleri:**

- ğŸ”´ **KÄ±rmÄ±zÄ± Daireler:** En Ã¶nemli 15 akademisyen (PageRank skoruna gÃ¶re)
- ğŸ”µ **Renkli Daireler:** DiÄŸer akademisyenler (araÅŸtÄ±rma gruplarÄ±na gÃ¶re renklendirilmiÅŸ)
- ğŸ“ **Daire Boyutu:** PageRank skoruna gÃ¶re (ne kadar bÃ¼yÃ¼kse o kadar Ã¶nemli)
- â– **Ã‡izgi KalÄ±nlÄ±ÄŸÄ±:** Ortak yayÄ±n sayÄ±sÄ± (kalÄ±n = daha fazla ortak Ã§alÄ±ÅŸma)

**AÄŸ Ä°statistikleri Kutusu:**
- Toplam akademisyen sayÄ±sÄ±
- Toplam ortak Ã§alÄ±ÅŸma sayÄ±sÄ±
- AraÅŸtÄ±rma grubu sayÄ±sÄ±

### 3. ML Analizi SonuÃ§larÄ±

**Etki SkorlarÄ±:**

| Yazar | Etki Skoru | Toplam AtÄ±f | YayÄ±n | H-index | PageRank |
|-------|-----------|-------------|-------|---------|----------|
| I. Sutskever | 100.0 | 237,150 | 7 | 7 | 0.0044 |
| G. E. Hinton | 66.3 | 222,225 | 6 | 6 | 0.0023 |
| A. Krizhevsky | 44.2 | 165,704 | 2 | 2 | 0.0015 |

**Tahmin Modeli PerformansÄ± (GerÃ§ek SonuÃ§lar):**

```
Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±:
  RF           | RÂ² =  0.7251 | RMSE =  9988.18
  LGBM         | RÂ² =  0.7600 | RMSE =  9332.00
  DT           | RÂ² =  0.6595 | RMSE = 11115.87

En Ä°yi Model: LightGBM (LGBM)
- RÂ² = 0.7600 (Veri varyansÄ±nÄ±n %76'sÄ±nÄ± aÃ§Ä±klÄ±yor)
- RMSE = 9332.00 (Ortalama Â±9332 atÄ±f sapma)

En Ã–nemli Ã–zellikler (LightGBM Modeline GÃ¶re):
1. Total Citations (en yÃ¼ksek Ã¶nem)
2. H-index
3. PageRank
4. Publication Count
5. Network Metrikleri (Betweenness, Eigenvector, vb.)
```

---

## ğŸ“ˆ Performans Metrikleri

### Veri Toplama PerformansÄ±

- **API BaÅŸarÄ± OranÄ±:** %95+ (retry mekanizmasÄ± ile)
- **Ortalama Ä°stek SÃ¼resi:** 3-5 saniye
- **Rate Limit Uyumu:** %100 (otomatik bekleme)

### Analiz PerformansÄ±

- **Veri Ä°ÅŸleme HÄ±zÄ±:** 1000 yayÄ±n/saniye
- **Network Analizi:** 500 dÃ¼ÄŸÃ¼m iÃ§in < 10 saniye
- **ML Model EÄŸitimi:** < 10 saniye (3 model: RF, LGBM, DT)

### Model DoÄŸruluÄŸu (GerÃ§ek SonuÃ§lar)

- **En Ä°yi Model:** LightGBM (LGBM)
- **RÂ² Skoru:** 0.7600 (Veri varyansÄ±nÄ±n %76'sÄ±nÄ± aÃ§Ä±klÄ±yor)
- **RMSE:** 9332.00 (Ortalama Â±9332 atÄ±f sapma)
- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:**
  - LightGBM: RÂ² = 0.76, RMSE = 9332
  - Random Forest: RÂ² = 0.73, RMSE = 9988
  - Decision Tree: RÂ² = 0.66, RMSE = 11116

---

## ğŸ¯ SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar

### Proje BaÅŸarÄ±larÄ±

âœ… **BaÅŸarÄ±lÄ± API Entegrasyonu**
- Semantic Scholar API ile gÃ¼venilir veri toplama
- Rate limiting ve retry mekanizmasÄ±
- Otomatik pagination

âœ… **KapsamlÄ± Veri Analizi**
- Network analizi (PageRank, centrality)
- Coklu ML modelleri ile etki skoru hesaplama (RF, LGBM, DT)
- Model performans karsilastirmasi ve otomatik en iyi model secimi
- Topluluk tespiti (Louvain algoritmasi)

âœ… **Profesyonel GÃ¶rselleÅŸtirmeler**
- AnlaÅŸÄ±lÄ±r aÄŸ gÃ¶rselleÅŸtirmeleri
- DetaylÄ± istatistik kutularÄ±
- KullanÄ±cÄ± dostu legend'ler

âœ… **GÃ¼venilir SonuÃ§lar**
- Duplicate kontrolÃ¼
- Veri temizleme ve normalizasyon
- Hata yÃ¶netimi

### Gelecek Ä°yileÅŸtirmeler

ğŸ”® **Daha Fazla Veri KaynaÄŸÄ±**
- Google Scholar entegrasyonu (API geliÅŸtirilirse)
- ArXiv, PubMed, IEEE Xplore
- Ã‡oklu kaynak birleÅŸtirme

ğŸ”® **GeliÅŸmiÅŸ ML Modelleri**
- Deep Learning modelleri (Neural Networks)
- Time-series analizi (yÄ±llara gÃ¶re trend)
- Hiperparametre optimizasyonu (GridSearchCV, Bayesian Optimization)
- Model stacking ve blending teknikleri

ğŸ”® **Ä°nteraktif ArayÃ¼z**
- Web arayÃ¼zÃ¼ (Dash/Streamlit)
- Dinamik filtreleme ve arama
- GerÃ§ek zamanlÄ± gÃ¶rselleÅŸtirme

ğŸ”® **Daha DetaylÄ± Analizler**
- YayÄ±n konularÄ±na gÃ¶re kategorizasyon (NLP)
- CoÄŸrafi analiz (kurumlar, Ã¼lkeler)
- Zaman bazlÄ± trend analizi
- Yazar benzerlik analizi (cosine similarity)

---

## ğŸ“ Teknik Ã–zellikler

### KullanÄ±lan Teknolojiler

| Kategori | Teknoloji | Versiyon | KullanÄ±m AmacÄ± |
|----------|-----------|----------|----------------|
| **API** | Semantic Scholar API | v1 | Veri toplama |
| **HTTP** | Requests | 2.31+ | API istekleri |
| **Veri Ä°ÅŸleme** | Pandas | 2.2+ | DataFrame iÅŸlemleri |
| **SayÄ±sal** | NumPy | 1.26+ | Matematiksel hesaplamalar |
| **Network** | NetworkX | 3.2.1 | AÄŸ analizi |
| **Topluluk** | Python-Louvain | 0.16 | Topluluk tespiti |
| **ML** | Scikit-learn | 1.4+ | ML modelleri (RF, DT) |
| **ML** | LightGBM | 4.1+ | Gradient boosting modeli |
| **GÃ¶rselleÅŸtirme** | Matplotlib | 3.9+ | Grafikler |

### Sistem Gereksinimleri

- **Python:** 3.8+
- **RAM:** Minimum 4GB (Ã¶nerilen: 8GB+)
- **Disk:** 500MB (veriler ve sonuÃ§lar iÃ§in)
- **Ä°nternet:** API eriÅŸimi iÃ§in

---

## ğŸš€ KullanÄ±m KÄ±lavuzu

### Kurulum

```bash
# 1. Repository'yi klonlayÄ±n
git clone <repository-url>
cd academic_analysis

# 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt

# 3. Projeyi Ã§alÄ±ÅŸtÄ±rÄ±n
python src/main.py
```

### Ã–zelleÅŸtirme

**Arama SorgularÄ±nÄ± DeÄŸiÅŸtirme:**

```python
# src/main.py dosyasÄ±nda
queries = [
    "machine learning",
    "deep learning",
    "neural networks",
    "natural language processing"  # Yeni sorgu ekle
]
```

**API Key Kullanma (Rate Limit ArtÄ±rma):**

```python
collector = ScholarDataCollector(
    api_key="YOUR_API_KEY",  # Semantic Scholar'dan alÄ±n
    delay=3.0,
    timeout=30.0
)
```

**GÃ¶rselleÅŸtirme AyarlarÄ±:**

```python
network_analyzer.visualize_network(
    top_authors=50,           # GÃ¶sterilecek yazar sayÄ±sÄ±
    figsize=(24, 16),         # GÃ¶rsel boyutu
    min_edge_weight=2         # Minimum baÄŸlantÄ± aÄŸÄ±rlÄ±ÄŸÄ±
)
```

---

## ğŸ“š Referanslar ve Kaynaklar

### API DokÃ¼mantasyonu

- **Semantic Scholar API:** https://www.semanticscholar.org/product/api
- **Rate Limits:** 100 istek/5 dakika (API key ile: 5000 istek/5 dakika)

### KÃ¼tÃ¼phane DokÃ¼mantasyonlarÄ±

- **NetworkX:** https://networkx.org/documentation/stable/
- **Scikit-learn:** https://scikit-learn.org/stable/
- **Pandas:** https://pandas.pydata.org/docs/

### Algoritma ReferanslarÄ±

- **PageRank:** Page, L., et al. (1999). "The PageRank Citation Ranking"
- **Louvain Algorithm:** Blondel, V. D., et al. (2008). "Fast unfolding of communities"
- **H-index:** Hirsch, J. E. (2005). "An index to quantify an individual's scientific research output"

---

## ğŸ™ TeÅŸekkÃ¼rler

Bu proje, akademik araÅŸtÄ±rma topluluklarÄ±nÄ± anlamak ve bilimsel iÅŸbirliklerini analiz etmek iÃ§in geliÅŸtirilmiÅŸtir.

**KullanÄ±lan AÃ§Ä±k Kaynak KÃ¼tÃ¼phaneler:**
- NetworkX - AÄŸ analizi
- Scikit-learn - Makine Ã¶ÄŸrenmesi
- Pandas - Veri iÅŸleme
- Matplotlib - GÃ¶rselleÅŸtirme
- Semantic Scholar API - Veri kaynaÄŸÄ±

---

<div style="text-align: center; margin: 40px 0; padding: 20px; background-color: #f5f5f5; border-radius: 10px;">

## ğŸ“§ Ä°letiÅŸim ve KatkÄ±

Proje aÃ§Ä±k kaynak kodludur ve katkÄ±lara aÃ§Ä±ktÄ±r.

**Lisans:** MIT License

**GitHub:** [Repository URL]

---

**Sunum Sonu**

*Akademik YayÄ±n Analizi ve AtÄ±f AÄŸÄ± Projesi*

*Makine Ã–ÄŸrenmesi ile Yazar Etki Analizi ve Network Analizi*

</div>