"""
Ortak YazarlÄ±k AÄŸÄ± Analizi ve GÃ¶rselleÅŸtirme ModÃ¼lÃ¼

Bu modÃ¼l, yazarlar arasÄ± ortak yazarlÄ±k iliÅŸkilerini analiz eder:
- Ortak yazarlÄ±k aÄŸÄ± oluÅŸturur
- AÄŸ metrikleri hesaplar (PageRank, centrality vb.)
- AraÅŸtÄ±rma topluluklarÄ±nÄ± tespit eder
- AÄŸÄ± gÃ¶rselleÅŸtirir
"""

import networkx as nx
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from collections import defaultdict
import matplotlib.pyplot as plt


class CitationNetworkAnalyzer:
    """
    Ortak YazarlÄ±k AÄŸÄ± Analizi SÄ±nÄ±fÄ±
    
    Yazarlar arasÄ± ortak Ã§alÄ±ÅŸma iliÅŸkilerini analiz eder ve gÃ¶rselleÅŸtirir.
    """
    
    def __init__(self, publications_df: pd.DataFrame, authors_df: pd.DataFrame):
        """
        Args:
            publications_df: YayÄ±n verilerini iÃ§eren DataFrame
            authors_df: Yazar-yayÄ±n iliÅŸkilerini iÃ§eren DataFrame (normalize edilmiÅŸ)
        """
        self.publications_df = publications_df
        self.authors_df = authors_df
        self.coauthorship_graph = nx.Graph()  # Ortak yazarlÄ±k aÄŸÄ±
    
    def build_coauthorship_network(self) -> nx.Graph:
        """
        Yazarlar arasÄ± ortak yazarlÄ±k aÄŸÄ±nÄ± oluÅŸturur
        
        AynÄ± yayÄ±nda birlikte yazmÄ±ÅŸ yazarlar arasÄ±nda baÄŸlantÄ± (edge) oluÅŸturur.
        Edge aÄŸÄ±rlÄ±ÄŸÄ±, yazarlarÄ±n birlikte yazdÄ±ÄŸÄ± yayÄ±n sayÄ±sÄ±nÄ± gÃ¶sterir.
        
        Returns:
            Ortak yazarlÄ±k aÄŸÄ± (NetworkX Graph)
        """
        self.coauthorship_graph = nx.Graph()
        
        # Her yayÄ±ndaki yazarlarÄ± iÅŸle
        for idx, row in self.publications_df.iterrows():
            authors = row.get('authors', [])
            
            # En az 2 yazar olmalÄ± (ortak yazarlÄ±k iÃ§in)
            if not authors or len(authors) < 2:
                continue
            
            # Yazar isimlerini normalize et (kÃ¼Ã§Ã¼k harf, boÅŸluk temizleme)
            normalized_authors = []
            for author in authors:
                if isinstance(author, str):
                    normalized = author.lower().strip()
                    normalized = normalized.replace('  ', ' ')
                    normalized_authors.append(normalized)
            
            # Her yazar Ã§ifti arasÄ±nda edge oluÅŸtur
            # Ã–rnek: [A, B, C] -> (A-B), (A-C), (B-C) baÄŸlantÄ±larÄ±
            for i in range(len(normalized_authors)):
                for j in range(i + 1, len(normalized_authors)):
                    author1 = normalized_authors[i]
                    author2 = normalized_authors[j]
                    
                    if self.coauthorship_graph.has_edge(author1, author2):
                        # Edge zaten varsa, aÄŸÄ±rlÄ±ÄŸÄ± artÄ±r (ortak yayÄ±n sayÄ±sÄ±)
                        self.coauthorship_graph[author1][author2]['weight'] += 1
                        self.coauthorship_graph[author1][author2]['publications'].append(
                            row.get('title', '')
                        )
                    else:
                        # Yeni edge oluÅŸtur
                        self.coauthorship_graph.add_edge(
                            author1, 
                            author2,
                            weight=1,  # Ä°lk ortak yayÄ±n
                            publications=[row.get('title', '')]
                        )
        
        return self.coauthorship_graph
    
    def calculate_network_metrics(self) -> pd.DataFrame:
        """
        AÄŸ metriklerini hesaplar
        
        Her yazar iÃ§in aÄŸdaki Ã¶nemini Ã¶lÃ§en metrikler:
        - degree: Direkt baÄŸlantÄ± sayÄ±sÄ±
        - degree_centrality: Normalize edilmiÅŸ baÄŸlantÄ± sayÄ±sÄ±
        - betweenness_centrality: AÄŸdaki kÃ¶prÃ¼ rolÃ¼
        - closeness_centrality: DiÄŸer yazarlara yakÄ±nlÄ±k
        - eigenvector_centrality: Ã–nemli yazarlarla baÄŸlantÄ±
        - pagerank: Genel Ã¶nem skoru
        
        Returns:
            Yazar metriklerini iÃ§eren DataFrame
        """
        if len(self.coauthorship_graph.nodes()) == 0:
            self.build_coauthorship_network()
        
        metrics = []
        
        # AÄŸ metriklerini hesapla
        degree_centrality = nx.degree_centrality(self.coauthorship_graph)
        betweenness_centrality = nx.betweenness_centrality(self.coauthorship_graph)
        closeness_centrality = nx.closeness_centrality(self.coauthorship_graph)
        eigenvector_centrality = nx.eigenvector_centrality(
            self.coauthorship_graph, 
            max_iter=1000
        )
        pagerank = nx.pagerank(self.coauthorship_graph)
        
        # Yazar istatistikleri ile birleÅŸtir
        for node in self.coauthorship_graph.nodes():
            degree = self.coauthorship_graph.degree(node)
            
            metrics.append({
                'author_name': node,
                'degree': degree,
                'degree_centrality': degree_centrality.get(node, 0),
                'betweenness_centrality': betweenness_centrality.get(node, 0),
                'closeness_centrality': closeness_centrality.get(node, 0),
                'eigenvector_centrality': eigenvector_centrality.get(node, 0),
                'pagerank': pagerank.get(node, 0)
            })
        
        metrics_df = pd.DataFrame(metrics)
        
        # author_name kolonunu korumak iÃ§in kopyala
        author_names = metrics_df['author_name'].copy()
        
        # Yazar istatistikleri ile birleÅŸtir
        # Ã–NEMLÄ°: authors_df'de aynÄ± yazar iÃ§in birden fazla satÄ±r olabilir (yazar-yayÄ±n iliÅŸkileri)
        # Bu yÃ¼zden Ã¶nce unique yazarlarÄ± almalÄ±yÄ±z
        if 'author_normalized' in self.authors_df.columns:
            # author_normalized kolonunu geÃ§ici olarak author_name olarak kullan
            authors_for_merge = self.authors_df.copy()
            
            # EÄŸer author_name zaten varsa, onu kaldÄ±r (Ã§akÄ±ÅŸmayÄ± Ã¶nlemek iÃ§in)
            if 'author_name' in authors_for_merge.columns:
                authors_for_merge = authors_for_merge.drop(columns=['author_name'])
            
            # author_normalized'i author_name olarak rename et
            authors_for_merge = authors_for_merge.rename(columns={'author_normalized': 'author_name'})
            
            # AynÄ± yazar iÃ§in birden fazla satÄ±r olabilir - unique yazarlarÄ± al
            # Her yazar iÃ§in ilk satÄ±rÄ± al (veya aggregate yap)
            authors_unique = authors_for_merge.drop_duplicates(subset=['author_name'], keep='first')
            
            merged = pd.merge(
                metrics_df,
                authors_unique,
                on='author_name',
                how='left',
                suffixes=('', '_from_authors')
            )
        elif 'author_name' in self.authors_df.columns:
            # author_name varsa direkt merge et, ama Ã¶nce unique yazarlarÄ± al
            authors_unique = self.authors_df.drop_duplicates(subset=['author_name'], keep='first')
            
            merged = pd.merge(
                metrics_df,
                authors_unique,
                on='author_name',
                how='left',
                suffixes=('', '_from_authors')
            )
        else:
            merged = metrics_df
        
        # author_name kolonunun varlÄ±ÄŸÄ±nÄ± garanti et
        if 'author_name' not in merged.columns:
            merged['author_name'] = author_names.values[:len(merged)]
        
        # Son kontrol: duplicate'leri kaldÄ±r (gÃ¼venlik iÃ§in)
        merged = merged.drop_duplicates(subset=['author_name'], keep='first')
        
        return merged
    
    def find_research_communities(self, algorithm: str = 'louvain') -> Dict:
        """
        AraÅŸtÄ±rma topluluklarÄ±nÄ± bulur
        
        Benzer araÅŸtÄ±rma yapan yazarlarÄ± gruplar.
        Topluluk tespiti iÃ§in Louvain veya Girvan-Newman algoritmasÄ± kullanÄ±lÄ±r.
        
        Args:
            algorithm: Topluluk tespit algoritmasÄ± ('louvain' veya 'girvan_newman')
            
        Returns:
            Topluluk ID'sine gÃ¶re yazar listelerini iÃ§eren dict
            Ã–rnek: {0: ['author1', 'author2'], 1: ['author3', 'author4']}
        """
        if len(self.coauthorship_graph.nodes()) == 0:
            self.build_coauthorship_network()
        
        # Algoritma seÃ§imi
        if algorithm == 'louvain':
            try:
                import community as community_louvain
                communities = community_louvain.best_partition(self.coauthorship_graph)
            except ImportError:
                print("python-louvain kÃ¼tÃ¼phanesi bulunamadÄ±. Girvan-Newman algoritmasÄ± kullanÄ±lÄ±yor.")
                communities = self._girvan_newman_communities()
        elif algorithm == 'girvan_newman':
            communities = self._girvan_newman_communities()
        else:
            communities = self._girvan_newman_communities()
        
        # Topluluk bilgilerini organize et: {topluluk_id: [yazar_listesi]}
        community_dict = defaultdict(list)
        for node, comm_id in communities.items():
            community_dict[comm_id].append(node)
        
        return dict(community_dict)
    
    def _girvan_newman_communities(self) -> Dict:
        """
        Girvan-Newman algoritmasÄ± ile topluluk bulma
        
        Edge betweenness'e gÃ¶re topluluklarÄ± ayÄ±rÄ±r.
        
        Returns:
            {node: community_id} formatÄ±nda dict
        """
        communities_generator = nx.community.girvan_newman(self.coauthorship_graph)
        
        # Ä°lk iterasyonu al (en iyi bÃ¶lÃ¼nme)
        top_level_communities = next(communities_generator)
        
        communities = {}
        for i, comm in enumerate(top_level_communities):
            for node in comm:
                communities[node] = i
        
        return communities
    
    def get_top_connectors(self, top_n: int = 20) -> pd.DataFrame:
        """
        En Ã§ok baÄŸlantÄ±ya sahip yazarlarÄ± dÃ¶ndÃ¼rÃ¼r
        
        Args:
            top_n: DÃ¶ndÃ¼rÃ¼lecek yazar sayÄ±sÄ±
            
        Returns:
            En Ã§ok baÄŸlantÄ±ya sahip yazarlarÄ± iÃ§eren DataFrame
        """
        metrics_df = self.calculate_network_metrics()
        # Duplicate'leri kaldÄ±r (her yazar iÃ§in sadece bir satÄ±r)
        metrics_df = metrics_df.drop_duplicates(subset=['author_name'], keep='first')
        top_connectors = metrics_df.nlargest(top_n, 'degree')
        return top_connectors
    
    def visualize_network(
        self, 
        top_authors: int = 30,  # Daha az dÃ¼ÄŸÃ¼m - daha okunabilir
        figsize: Tuple[int, int] = (24, 16),
        node_size_factor: float = 800,
        save_path: str = None,
        min_edge_weight: int = 2  # Sadece gÃ¼Ã§lÃ¼ baÄŸlantÄ±larÄ± gÃ¶ster
    ):
        """AÄŸÄ± gÃ¶rselleÅŸtirir - SadeleÅŸtirilmiÅŸ ve okunabilir versiyon"""
        if len(self.coauthorship_graph.nodes()) == 0:
            self.build_coauthorship_network()
        
        # En Ã¶nemli yazarlarÄ± seÃ§ (PageRank'e gÃ¶re - daha iyi Ã¶nem Ã¶lÃ§Ã¼sÃ¼)
        metrics_df = self.calculate_network_metrics()
        # Duplicate'leri kaldÄ±r (gÃ¼venlik iÃ§in)
        metrics_df = metrics_df.drop_duplicates(subset=['author_name'], keep='first')
        top_authors_list = metrics_df.nlargest(top_authors, 'pagerank')['author_name'].tolist()
        
        # Alt grafi oluÅŸtur
        subgraph = self.coauthorship_graph.subgraph(top_authors_list).copy()
        
        if len(subgraph.nodes()) == 0:
            print("[WARNING] Gorsellestirme icin yeterli dugum yok!")
            return
        
        # ZayÄ±f kenarlarÄ± filtrele (sadece gÃ¼Ã§lÃ¼ baÄŸlantÄ±larÄ± gÃ¶ster)
        edges_to_remove = [(u, v) for u, v, d in subgraph.edges(data=True) 
                           if d.get('weight', 1) < min_edge_weight]
        subgraph.remove_edges_from(edges_to_remove)
        
        # Ä°zole dÃ¼ÄŸÃ¼mleri kaldÄ±r
        isolated = list(nx.isolates(subgraph))
        subgraph.remove_nodes_from(isolated)
        
        if len(subgraph.nodes()) == 0:
            print("[WARNING] Filtreleme sonrasi dugum kalmadi!")
            return
        
        # TopluluklarÄ± bul (renklendirme iÃ§in)
        try:
            import community.community_louvain as community_louvain
            communities = community_louvain.best_partition(subgraph)
        except:
            # community modÃ¼lÃ¼ yoksa, degree'e gÃ¶re grupla
            communities = {}
            degrees = dict(subgraph.degree())
            sorted_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)
            num_communities = min(10, len(sorted_nodes))
            for idx, (node, _) in enumerate(sorted_nodes):
                communities[node] = idx % num_communities
        
        # Renk paleti (daha canlÄ± renkler)
        import matplotlib.cm as cm
        num_communities = len(set(communities.values()))
        colors = cm.Set3(np.linspace(0, 1, max(num_communities, 1)))
        node_colors = [colors[communities.get(node, 0) % len(colors)] for node in subgraph.nodes()]
        
        # Layout - Daha iyi daÄŸÄ±lÄ±m iÃ§in (daha fazla boÅŸluk)
        try:
            pos = nx.spring_layout(subgraph, k=3, iterations=200, weight='weight', seed=42)
        except:
            try:
                pos = nx.kamada_kawai_layout(subgraph, weight='weight')
            except:
                pos = nx.spring_layout(subgraph, k=2, iterations=100)
        
        # Ã‡izim
        fig, ax = plt.subplots(figsize=figsize, facecolor='white')
        
        # Node boyutlarÄ± (sadece PageRank'e gÃ¶re - daha anlamlÄ±)
        pagerank_values = nx.pagerank(subgraph)
        max_pr = max(pagerank_values.values()) if pagerank_values.values() else 1
        
        node_sizes = []
        for node in subgraph.nodes():
            pr = pagerank_values.get(node, 0)
            # PageRank'e gÃ¶re boyut (normalize edilmiÅŸ)
            size = (pr / max_pr) * node_size_factor + 300  # Minimum 300
            node_sizes.append(size)
        
        # Edge aÄŸÄ±rlÄ±klarÄ± ve renkleri
        edges = subgraph.edges()
        weights = [subgraph[u][v].get('weight', 1) for u, v in edges]
        max_weight = max(weights) if weights else 1
        
        # KenarlarÄ± Ã§iz (Ã¶nce, bÃ¶ylece node'lar Ã¼stte kalÄ±r)
        # Sadece gÃ¼Ã§lÃ¼ baÄŸlantÄ±larÄ± daha kalÄ±n gÃ¶ster
        edge_widths = [min(w / max_weight * 3, 2.5) for w in weights]
        
        nx.draw_networkx_edges(
            subgraph,
            pos,
            width=edge_widths,
            alpha=0.3,  # Daha ÅŸeffaf - daha az dikkat daÄŸÄ±tÄ±cÄ±
            edge_color='#888888',
            style='solid',
            ax=ax
        )
        
        # En Ã¶nemli node'larÄ± belirle (PageRank'e gÃ¶re)
        important_nodes = sorted(pagerank_values.items(), key=lambda x: x[1], reverse=True)[:15]
        important_node_names = [node for node, _ in important_nodes]
        
        # Node'larÄ± Ã§iz - Ã¶nemli node'lar daha belirgin
        node_colors_final = []
        node_edge_widths = []
        for node in subgraph.nodes():
            if node in important_node_names:
                node_colors_final.append('#FF6B6B')  # KÄ±rmÄ±zÄ± - Ã¶nemli
                node_edge_widths.append(3.0)
            else:
                node_colors_final.append(node_colors[list(subgraph.nodes()).index(node)])
                node_edge_widths.append(1.5)
        
        nx.draw_networkx_nodes(
            subgraph, 
            pos, 
            node_size=node_sizes,
            node_color=node_colors_final,
            alpha=0.85,
            edgecolors='black',
            linewidths=node_edge_widths,
            ax=ax
        )
        
        labels = {}
        for node in important_node_names:
            if node in subgraph.nodes():
                name_parts = str(node).split()
                if len(name_parts) > 1:
                    label = name_parts[-1].upper()  # Son isim, bÃ¼yÃ¼k harf
                else:
                    label = str(node)[:12].upper()
                labels[node] = label
        
        # Etiketleri Ã§iz - sadece Ã¶nemli node'lar iÃ§in (daha okunabilir)
        for node, label in labels.items():
            x, y = pos[node]
            # Ã–nemli yazarlar iÃ§in daha belirgin etiket
            ax.text(x, y, label, 
                   fontsize=12,
                   ha='center', va='center',
                   bbox=dict(boxstyle='round,pad=0.6', 
                           facecolor='#FFE5E5',  # AÃ§Ä±k kÄ±rmÄ±zÄ± arka plan
                           edgecolor='#FF6B6B',  # KÄ±rmÄ±zÄ± kenar
                           linewidth=2,
                           alpha=0.95),
                   fontweight='bold',
                   color='#8B0000')  # Koyu kÄ±rmÄ±zÄ± yazÄ±
        
        # Ana baÅŸlÄ±k - Projenin ne yaptÄ±ÄŸÄ±nÄ± aÃ§Ä±kÃ§a belirt
        main_title = 'AKADEMÄ°K YAYIN ANALÄ°ZÄ°: ORTAK YAZARLIK AÄI'
        subtitle = f'Bu gÃ¶rsel, {len(subgraph.nodes())} akademisyenin birbirleriyle yaptÄ±ÄŸÄ± ortak Ã§alÄ±ÅŸmalarÄ± gÃ¶sterir'
        
        ax.text(0.5, 0.98, main_title,
               transform=ax.transAxes,
               fontsize=24, fontweight='bold',
               ha='center', va='top',
               color='#1a1a1a')
        
        ax.text(0.5, 0.94, subtitle,
               transform=ax.transAxes,
               fontsize=14,
               ha='center', va='top',
               color='#555555',
               style='italic')
        
        # AÃ§Ä±klayÄ±cÄ± bilgi kutusu - Sol Ã¼st
        info_text = (
            '[INFO] AG ISTATISTIKLERI\n'
            f'â€¢ {len(subgraph.nodes())} Akademisyen\n'
            f'â€¢ {len(subgraph.edges())} Ortak Ã‡alÄ±ÅŸma\n'
            f'â€¢ {num_communities} AraÅŸtÄ±rma Grubu'
        )
        ax.text(0.02, 0.88, info_text,
               transform=ax.transAxes,
               fontsize=12,
               verticalalignment='top',
               bbox=dict(boxstyle='round,pad=1.0', 
                        facecolor='#E8F4F8', 
                        edgecolor='#2C5F7D', 
                        linewidth=2, 
                        alpha=0.95),
               color='#1a1a1a')
        
        # Legend/Efsane - SaÄŸ Ã¼st
        legend_text = (
            'ğŸ”´ KIRMIZI DAÄ°RELER\n'
            'En Ã¶nemli 15 akademisyen\n'
            '(PageRank skoruna gÃ¶re)\n\n'
            'ğŸ”µ RENKLÄ° DAÄ°RELER\n'
            'DiÄŸer akademisyenler\n'
            '(AraÅŸtÄ±rma gruplarÄ±na gÃ¶re\n'
            'renklendirilmiÅŸ)\n\n'
            'ğŸ“ DAÄ°RE BOYUTU\n'
            'Ne kadar bÃ¼yÃ¼kse,\n'
            'o kadar Ã¶nemli\n'
            '(PageRank skoruna gÃ¶re)\n\n'
            'â– Ã‡Ä°ZGÄ°LER\n'
            'Ortak yayÄ±n sayÄ±sÄ±\n'
            '(KalÄ±n = Daha fazla)'
        )
        ax.text(0.98, 0.88, legend_text,
               transform=ax.transAxes,
               fontsize=11,
               verticalalignment='top',
               ha='right',
               bbox=dict(boxstyle='round,pad=1.0', 
                        facecolor='#FFF9E6', 
                        edgecolor='#D4A574', 
                        linewidth=2, 
                        alpha=0.95),
               color='#1a1a1a')
        
        # Alt aÃ§Ä±klama - Alt kÄ±sÄ±m
        footer_text = (
            'Bu analiz, akademik yayÄ±nlardan toplanan verilerle oluÅŸturulmuÅŸtur. '
            'Her daire bir akademisyeni, her Ã§izgi ortak Ã§alÄ±ÅŸmayÄ± temsil eder.'
        )
        ax.text(0.5, 0.02, footer_text,
               transform=ax.transAxes,
               fontsize=11,
               ha='center', va='bottom',
               style='italic',
               color='#666666',
               bbox=dict(boxstyle='round,pad=0.5', 
                        facecolor='#F5F5F5', 
                        edgecolor='#CCCCCC', 
                        linewidth=1, 
                        alpha=0.8))
        
        plt.axis('off')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
            print(f"[OK] Gorsellestirme {save_path} dosyasina kaydedildi.")
        
        plt.tight_layout()
        plt.show()

